import pandas as pd
import numpy as np
import os
from typing import Optional

def run_ncp_peh15(input_file_path: str, ruta_salida_dat: str, dest_date: Optional[str] = None):
    """
    Procesa la hoja 'PEH' del archivo data.xlsx (ruta completa dada por input_file_path), 
    la desagrupa a 15 minutos, y genera el archivo Hydro_bids_15.dat.

    Parámetros:
    input_file_path (str): La ruta COMPLETA al archivo data.xlsx.
    ruta_salida_dat (str): La ruta al directorio donde se guardará Hydro_bids_15.dat.
    dest_date (str, opcional): La fecha de destino.
    """
    # --- CONFIGURACIÓN ---
    input_sheet_name = 'PEH' # <--- Nombre de la hoja de Excel
    output_file_name = 'Hydro_bids_15.dat'
    
    # Rutas de entrada y salida
    full_input_path = input_file_path  # <--- Usamos la ruta completa directamente
    full_output_path = os.path.join(ruta_salida_dat, output_file_name)

    print(f"Buscando archivo de ENTRADA en: {full_input_path}")
    print(f"Leyendo hoja: {input_sheet_name}")
    print(f"Ruta de SALIDA esperada: {full_output_path}")

    chunk_size = 10000 
    MINUTE_INTERVALS = [0, 15, 30, 45]
    DEFAULT_LEVEL = 1  
    NA_REPLACEMENT_VALUE = '0' 

    print(f"--- INICIO DEL PROCESO DE CONVERSIÓN (Archivo_NCP_PEH15 - Fuente: {full_input_path}/{input_sheet_name}) ---")

    # 1. Lectura del archivo EXCEL
    print(f"\n1. Intentando leer la hoja '{input_sheet_name}' del archivo Excel...")
    try:
        # Usamos pd.read_excel para leer la hoja PEH
        df = pd.read_excel(full_input_path, sheet_name=input_sheet_name)
        print(f"   -> Lectura exitosa de la hoja '{input_sheet_name}'.")
    except FileNotFoundError:
        print(f"   -> ERROR: Archivo '{full_input_path}' no encontrado.")
        raise FileNotFoundError(f"Archivo '{full_input_path}' no encontrado.")
    except ValueError as e:
        print(f"   -> ERROR: Hoja '{input_sheet_name}' no encontrada o formato incorrecto. {e}")
        raise ValueError(f"Hoja '{input_sheet_name}' no encontrada en el archivo: {full_input_path}")
    except Exception as e:
        print(f"   -> ERROR al leer el archivo Excel: {e}")
        raise Exception(f"Error al leer el archivo Excel: {e}")

    print(f"   -> Filas leídas: {len(df):,}")


    # 2. Limpieza de columnas y desagregación a nivel de 15 minutos
    print("\n2. Limpieza y desagregación a nivel de 15 minutos...")

    # Mapeo de los nombres de columna del nuevo archivo a nombres estándar
    NEW_COLUMN_MAPPING = {
        '!dd': 'DIA', 'mm': 'MES', 'aaaa': 'ANIO', 
        'hh': 'HORA', 'mm.1': 'MINUTO_ORIGINAL', 'level': 'NIVEL_ORIGINAL'
    }
    
    time_cols_base = ['DIA', 'MES', 'ANIO', 'HORA']

    # Aplicar limpieza de encabezados (mejorada y robusta)
    df.columns = (df.columns
                  .astype(str) 
                  .str.strip('\'"') 
                  .str.strip())       

    df.rename(columns=NEW_COLUMN_MAPPING, inplace=True)

    # Conversión y limpieza de las columnas de tiempo base
    for col in time_cols_base:
        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')

    df.dropna(subset=time_cols_base, inplace=True)
    
    # Identificar columnas de datos
    mapped_values = list(NEW_COLUMN_MAPPING.values())
    all_known_cols = set(time_cols_base + mapped_values)
    data_cols = [col for col in df.columns if col not in all_known_cols]
    
    # Convertir columnas de datos a numérico
    for col in data_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')


    # --- CLAVE: DUPLICACIÓN DE FILAS PARA 15 MINUTOS (CROSS JOIN) ---
    print("   -> Duplicando cada fila para resolución de 15 minutos (método eficiente)...")

    minutes_df = pd.DataFrame({'MINUTO': MINUTE_INTERVALS})
    df_15min = pd.merge(df[time_cols_base + data_cols].copy(), minutes_df, how='cross')

    df_15min['NIVEL'] = DEFAULT_LEVEL

    time_cols_final = ['DIA', 'MES', 'ANIO', 'HORA', 'MINUTO', 'NIVEL']
    output_cols_order = time_cols_final + data_cols
    df_final = df_15min[output_cols_order].copy()
    print(f"   -> Filas totales (4x el original): {len(df_final):,}")


    # 3. Creación de las líneas de salida en formato Archivo_NCP_PEH15
    print("\n3. Dando formato a las líneas de salida con estructura Archivo_NCP_PEH15...")

    def format_final_line_ncp(row, data_cols):
        time_part = f"{int(row['DIA']):02d},{int(row['MES']):02d},{int(row['ANIO'])},{int(row['HORA']):02d},{int(row['MINUTO']):02d},{int(row['NIVEL'])}"
        data_parts = []
        for col in data_cols:
            val = row[col]
            data_string = NA_REPLACEMENT_VALUE if pd.isna(val) else f"{val:.4f}".rstrip('0').rstrip('.')
            data_parts.append(data_string)
        return f"{time_part},{','.join(data_parts)}"

    df_final['DAT_LINE'] = df_final.apply(lambda row: format_final_line_ncp(row, data_cols), axis=1)

    total_lines = len(df_final)
    print(f"   -> Líneas de datos listas para escribir: {total_lines:,}")


    # 4. Guardar en el archivo Hydro_bids_15.dat
    print(f"\n4. Iniciando la escritura en '{full_output_path}'...")
    
    official_header_time_cols = ['!dd', 'mm', 'aaaa', 'hh', 'mm', 'level']
    header_cols = official_header_time_cols + data_cols
    header = [",".join(header_cols)]

    data_lines = df_final['DAT_LINE'].tolist()

    try:
        os.makedirs(ruta_salida_dat, exist_ok=True)
        
        with open(full_output_path, 'w') as f:
            f.write(header[0] + '\n')
            lines_written = 0

            for i in range(0, total_lines, chunk_size):
                chunk = data_lines[i:i + chunk_size]
                f.write('\n'.join(chunk) + '\n')
                lines_written += len(chunk)
    except Exception as e:
        print(f"   -> ERROR al escribir el archivo '{full_output_path}': {e}")
        raise Exception(f"Error al escribir el archivo de salida: {e}")

    print(f"\n--- PROCESO Archivo_NCP_PEH15 COMPLETADO ---")
    print(f"El archivo '{output_file_name}' ha sido creado con éxito en: {ruta_salida_dat}")

if __name__ == "__main__":
    print("Ejecución independiente: La lógica de prueba requiere modificación para Excel.")
    # La lógica de prueba aquí debe generar un 'data.xlsx' para que funcione.
